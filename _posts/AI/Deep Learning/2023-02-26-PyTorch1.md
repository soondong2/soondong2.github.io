---
title: "[PyTorch] 텐서 초기화 및 다차원 텐서"
date: 2023-02-26

categories:
  - AI
  - Deep Learning
tags:
    - Python
    - PyTorch
---

## 파이토치(PyTorch)

* 페이스북이 초기 루아(Lua) 언어로 개발된 토치(Torch)를 파이썬 버전으로 개발하여 2017년도에 공개
* 초기에 토치(Torch)는 넘파이(NumPy) 라이브러리처럼 과학 연산을 위한 라이브러리로 공개
* 이후 GPU를 이용한 텐서 조작 및 동적 신경망 구축이 가능하도록 딥러닝 프레임워크로 발전시킴
* 파이썬답게 만들어졌고, 유연하면서도 가속화된 계산 속도를 제공

## PyTorch 모듈 구조
![image](https://user-images.githubusercontent.com/100760303/221390292-8375fab4-8d2b-4df1-af91-79f3321a8d61.png)

## PyTorch 구성요소
- `torch`: 메인 네임스페이스, 텐서 등의 다양한 수학 함수가 포함
- `torch.autograd`: 자동 미분 기능을 제공하는 라이브러리
- `torch.nn`: 신경망 구축을 위한 데이터 구조나 레이어 등의 라이브러리
- `torch.multiprocessing`: 병럴처리 기능을 제공하는 라이브러리
- `torch.optim`: SGD(Stochastic Gradient Descent)를 중심으로 한 파라미터 최적화 알고리즘 제공
- `torch.utils`: 데이터 조작 등 유틸리티 기능 제공
- `torch.onnx`: ONNX(Open Neural Network Exchange), 서로 다른 프레임워크 간의 모델을 공유할 때 사용

## 텐서(Tensors)
* **데이터 표현을 위한 기본 구조**로 `텐서(tensor)`를 사용
* 텐서는 데이터를 담기위한 `컨테이너(container)`로서 일반적으로 수치형 데이터를 저장
* 넘파이(NumPy)의 `ndarray`와 유사
* GPU를 사용한 연산 가속 가능

![image](https://user-images.githubusercontent.com/100760303/221390304-0e95ad61-a797-4f84-bec6-a882c7a5073c.png)

```python
import torch
```


```python
torch.__version__
```




    '1.13.1+cpu'



## 텐서 초기화 타입


```python
# 초기화 되지 않은 텐서
x = torch.empty(4, 2)  # (4, 2)의 비어있는 텐서 생성
print(x)
```

    tensor([[0.0000e+00, 7.5670e-44],
            [1.3601e-05, 5.2306e+22],
            [8.4488e+20, 2.6310e+20],
            [2.0432e+20, 8.2656e-10]])
    


```python
# 무작위로 초기화된 텐서
x = torch.rand(4, 2)
print(x)
```

    tensor([[0.4313, 0.3425],
            [0.8856, 0.4106],
            [0.0210, 0.3053],
            [0.0146, 0.4980]])
    


```python
# 데이터 타입(dtype)이 long이고, 0으로 채워진 텐서
# long이기 때문에 소수점이 없이 정수형으로 초기화됨
x = torch.zeros(4, 2, dtype=torch.long)
print(x)
```

    tensor([[0, 0],
            [0, 0],
            [0, 0],
            [0, 0]])
    


```python
# 사용자가 입력한 값으로 텐서 초기화
x = torch.tensor([3, 2.3])
print(x)
```

    tensor([3.0000, 2.3000])
    


```python
# 2 x 4 크기, double 타입, 1로 채워진 텐서
x = x.new_ones(2, 4, dtype=torch.double)
print(x)
```

    tensor([[1., 1., 1., 1.],
            [1., 1., 1., 1.]], dtype=torch.float64)
    


```python
# x와 같은 크기, float 타입, 무작위로 채워진 텐서
x = torch.randn_like(x, dtype=torch.float)
print(x)
```

    tensor([[ 1.0850,  0.3757, -1.3753,  0.0375],
            [-0.7611, -0.9296,  2.0491,  0.0120]])
    


```python
# 텐서의 크기 계산
print(x.size())
```

    torch.Size([2, 4])
    

## 데이터 타입

| Data type | dtype | CPU tensor | GPU tensor |
| ------ | ------ | ------ | ------ |
| 32-bit floating point | `torch.float32` or `torch.float` |`torch.FloatTensor` | `torch.cuda.FloatTensor` |
| 64-bit floating point | `torch.float64` or `torch.double` |`torch.DoubleTensor` | `torch.cuda.DoubleTensor` |
| 16-bit floating point | `torch.float16` or `torch.half` |`torch.HalfTensor` | `torch.cuda.HalfTensor` |
| 8-bit integer(unsinged) | `torch.uint8` |`torch.ByteTensor` | `torch.cuda.ByteTensor` |
| 8-bit integer(singed) | `torch.int8` |`torch.CharTensor` | `torch.cuda.CharTensor` |
| 16-bit integer(signed) | `torch.int16` or `torch.short` |`torch.ShortTensor` | `torch.cuda.ShortTensor` |
| 32-bit integer(signed) | `torch.int32` or `torch.int` |`torch.IntTensor` | `torch.cuda.IntTensor` |
| 64-bit integer(signed) | `torch.int64` or `torch.long` |`torch.LongTensor` | `torch.cuda.LongTensor` |


```python
ft = torch.FloatTensor([1, 2, 3])
print(ft)
print(ft.dtype)
```

    tensor([1., 2., 3.])
    torch.float32
    


```python
# 기존의 ft의 타입을 변환
print(ft.short())
print(ft.int())
print(ft
.long())
```

    tensor([1, 2, 3], dtype=torch.int16)
    tensor([1, 2, 3], dtype=torch.int32)
    tensor([1, 2, 3])
    


```python
it = torch.IntTensor([1, 2, 3])
print(it)
print(it.dtype)
```

    tensor([1, 2, 3], dtype=torch.int32)
    torch.int32
    


```python
print(it.float())
print(it.double())
print(it.half())
```

    tensor([1., 2., 3.])
    tensor([1., 2., 3.], dtype=torch.float64)
    tensor([1., 2., 3.], dtype=torch.float16)
    

## CUDA Tensors
`.to` 메소드를 사용하여 텐서의 어떠한 장치(cpu, gpu)로도 옮길 수 있음


```python
x = torch.randn(1)
print(x)
print(x.item())
print(x.dtype)
```

    tensor([-0.0639])
    -0.0639069452881813
    torch.float32
    


```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

y = torch.ones_like(x, device=device)
print(y)

x = x.to(device)
print(x)

z = x + y
print(z)
print(z.to('cpu', torch.double))
```

    cpu
    tensor([1.])
    tensor([-0.0639])
    tensor([0.9361])
    tensor([0.9361], dtype=torch.float64)
    

## 다차원 텐서 표현

0D Tensor(Scalar)

* 하나의 숫자를 담고 있는 텐서(tensor)
* 축과 형상이 없음


```python
t0 = torch.tensor(0)
print(t0.ndim) # 차원
print(t0.shape)
print(t0) # 실제값
```

    0
    torch.Size([])
    tensor(0)
    

1D Tensor(Vector)

* 값들을 저장한 리스트와 유사한 텐서
* 하나의 축이 존재


```python
t1 = torch.tensor([1, 2, 3])
print(t1.ndim) # 차원
print(t1.shape)
print(t1) # 실제값
```

    1
    torch.Size([3])
    tensor([1, 2, 3])
    

2D Tensor(Matrix)

* `행렬`과 같은 모양으로 두개의 축이 존재
* 일반적인 수치, 통계 데이터셋이 해당
* 주로 샘플(samples)과 특성(features)을 가진 구조로 사용


```python
t2 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
print(t2.ndim) # 차원
print(t2.shape)
print(t2) # 실제값
```

    2
    torch.Size([3, 3])
    tensor([[1, 2, 3],
            [4, 5, 6],
            [7, 8, 9]])
    

3D Tensor

* `큐브(cube)`와 같은 모양으로 세개의 축이 존재
* 데이터가 연속된 시퀀스 데이터나 시간 축이 포함된 시계열 데이터에 해당
* 주식 가격 데이터셋, 시간에 따른 질병 발병 데이터 등이 존재
* 주로 샘플(samples), 타임스텝(timesteps), 특성(features)을 가진 구조로 사용 


```python
t3 = torch.tensor([[[1, 2, 3], [4, 5, 6], [7, 8, 9]],
                   [[1, 2, 3], [4, 5, 6], [7, 8, 9]],
                   [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])
print(t3.ndim) # 차원
print(t3.shape)
print(t3) # 실제값
```

    3
    torch.Size([3, 3, 3])
    tensor([[[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]],
    
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]],
    
            [[1, 2, 3],
             [4, 5, 6],
             [7, 8, 9]]])
    

4D Tensor

* 4개의 축
* 컬러 이미지 데이터가 대표적인 사례 (흑백 이미지 데이터는 3D Tensor로 가능)
* 주로 샘플(samples), 높이(height), 너비(width), 컬러 채널(channel)을 가진 구조로 사용

5D Tensor

* 5개의 축
* 비디오 데이터가 대표적인 사례
* 주로 샘플(samples), 프레임(frames), 높이(height), 너비(width), 컬러 채널(channel)을 가진 구조로 사용
